###############################
logstash-syslog:
  enabled: true
  antiAffinity: soft

  resources:
    limits:
      cpu: "5"
      memory: "2Gi"

  fullnameOverride: logstash-syslog #From Syslog to Kafka
  replicas: 5
  image: gcr.io/its-artifact-commons/logstash-loki
  imageTag: develop-3a0839b

  service:
    type: NodePort
    ports:
    - port: 5140
      protocol: TCP
      targetPort: 5140
      nodePort: 30140
      name: syslog-tcp

    - port: 5141
      protocol: UDP
      targetPort: 5141 
      nodePort: 30141
      name: syslog-udp

  extraEnvs:
    - name: LS_JAVA_OPTS
      value: "-Xmx256m -Xms256m"

    - name: DUMMY
      value: "000" # DUMMY env for pod restarting, DO NOT REMOVE this comment

    - name: CTI_RATE_LIMIT # Request/Sec
      value: "5" # Request/sec
    - name: CTI_ERROR_RATE_LIMIT # Request/5 minutes
      value: "10"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name

  logstashConfig:
    logstash.yml: |
      http.host: "0.0.0.0"
      pipeline.ecs_compatibility: "disabled"
      pipeline.workers: 4

  extraVolumeMounts:
    - name: scripts
      mountPath: /scripts/
      readOnly: true
    - name: configs
      mountPath: /configs/
      readOnly: true
  extraVolumes:
    - name: scripts
      configMap:
        name: ruby-filter-cm
    - name: configs
      configMap:
        name: ruby-config-cm

  logstashPipeline:
    logstash.conf: |      
      input {
        syslog {
          port => 5140
        }

        udp {
          port => 5141
          type => "syslog"
        }
      }

      filter {
        ruby {
          code => "event.set('destination', 'kafka')"
        }

        ruby {
          path => "/scripts/etl.rb"
          script_params => {}
        }
      }

      output {
        #stdout { codec => json_lines }
        kafka {
          bootstrap_servers => "kafka-ads-kafka-bootstrap.kafka-ads.svc.cluster.local:9092"
          codec => json
          topic_id => "kafka-ads-topic"
        }
      }

###############################
logstash-es:
  enabled: true
  antiAffinity: soft

  fullnameOverride: logstash-es #From kafka to ES
  replicas: 5
  image: gcr.io/its-artifact-commons/logstash-loki
  imageTag: develop-3a0839b
  resources:
    requests:
      cpu: "1"
      memory: "1Gi"
    limits:
      cpu: "1.5"
      memory: "3Gi"
  extraEnvs:
    - name: ES_USER
      valueFrom:
        secretKeyRef:
          name: es-ads-basic-authen
          key: username
    - name: ES_PASSWORD
      valueFrom:
        secretKeyRef:
          name: es-ads-basic-authen
          key: password
    - name: DUMMY
      value: "000"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name

  logstashConfig:
    logstash.yml: |
      http.host: "0.0.0.0"
      pipeline.ecs_compatibility: "disabled"

  extraVolumeMounts:
    - name: scripts
      mountPath: /scripts/
      readOnly: true
    - name: configs
      mountPath: /configs/
      readOnly: true

  extraVolumes:
    - name: scripts
      configMap:
        name: ruby-filter-cm
    - name: configs
      configMap:
        name: ruby-config-cm

  logstashPipeline:
    logstash.conf: |
      input {
        kafka {
          bootstrap_servers => "kafka-ads-kafka-bootstrap.kafka-ads.svc.cluster.local:9092"
          group_id => "for-es"
          consumer_threads => 1
          topics => ["kafka-ads-topic", "kafka-ads-topic-beat"]
          codec => "json"
          type => "log"
          auto_offset_reset => "earliest"
        }
      }
      
      filter {
        ruby {
          code => "event.set('destination', 'loki')"
        }

        ruby {
          path => "/scripts/etl.rb"
          script_params => {}
        }

        prune {
          interpolate => true
          whitelist_names => [ "type", "mt", "@timestamp", "message", "ads_", "ndr_" ]
        }
      }

      output {
        #stdout { codec => rubydebug }        

        # To use ES change type back to "es"
        elasticsearch {
          hosts => [ "https://es-ads-es-http.es-ads.svc.cluster.local:9200" ]
          ssl_certificate_verification => false
          user => "${ES_USER}"
          password => "${ES_PASSWORD}"
          action => "create"

          ecs_compatibility => "v8"
          http_compression => "true"

          index => "rtarf-events-soc-%{[ads_ts_yyyy]}%{[ads_ts_mm]}%{[ads_ts_dd]}-%{[mt][pod_name_loki]}"
          template_name => "rtarf-events-soc"
          template => "/configs/es-template.json"
          template_overwrite => "true"
          timeout => "0.5"
        }
      }

###############################
logstash-es-child:
  enabled: true
  antiAffinity: soft

  fullnameOverride: logstash-es-child #From kafka to ES
  replicas: 3
  image: gcr.io/its-artifact-commons/logstash-loki
  imageTag: develop-3a0839b
  resources:
    requests:
      cpu: "1"
      memory: "1Gi"
    limits:
      cpu: "1.5"
      memory: "3Gi"
  extraEnvs:
    - name: ES_USER
      valueFrom:
        secretKeyRef:
          name: es-ads-basic-authen
          key: username
    - name: ES_PASSWORD
      valueFrom:
        secretKeyRef:
          name: es-ads-basic-authen
          key: password
    - name: DUMMY
      value: "008"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name

  logstashConfig:
    logstash.yml: |
      http.host: "0.0.0.0"
      pipeline.ecs_compatibility: "disabled"

  extraVolumeMounts:
    - name: scripts
      mountPath: /scripts/
      readOnly: true

  extraVolumes:
    - name: scripts
      configMap:
        name: es-child-filter-cm

  logstashPipeline:
    logstash.conf: |
      input {
        kafka {
          bootstrap_servers => "kafka-ads-kafka-bootstrap.kafka-ads.svc.cluster.local:9092"
          group_id => "for-es-child"
          consumer_threads => 1
          topics => ["kafka-ads-topic"]
          codec => "json"
          type => "log"
          auto_offset_reset => "earliest"
        }
      }

      filter {

        ruby {
          path => "/scripts/es-child.rb"
          script_params => {}
        }

        prune {
          interpolate => true
          whitelist_names => [ 
            "@timestamp", 
            "ads_child", 
            "ads_ts_yyyy", 
            "ads_ts_mm", 
            "ads_ts_dd", 
            "ads_pod_name_es",
            "ads_ref_key",
            "ads_category",
            "ads_log_group",
            "ads_log_source",
            "ads_device_type",
            "ads_host",
            
            "ads_dst_ip",
            "ads_dst_port",
            "ads_dst_zone",

            "ads_src_ip",
            "ads_src_port",
            "ads_src_zone",

            "ads_ip_dst",
            "ads_ip_src"
          ]
        }

        split {
          field => "ads_child"
        }
      }

      output {
        #stdout { codec => rubydebug }        

        # To use ES change type back to "es"
        elasticsearch {
          hosts => [ "https://es-ads-es-http.es-ads.svc.cluster.local:9200" ]
          ssl_certificate_verification => false
          user => "${ES_USER}"
          password => "${ES_PASSWORD}"
          action => "create"

          ecs_compatibility => "v8"
          http_compression => "true"

          index => "ads-child-events-%{[ads_ts_yyyy]}%{[ads_ts_mm]}%{[ads_ts_dd]}-%{[ads_pod_name_es]}"
          template_overwrite => "true"
          timeout => "0.5"
        }
      }
